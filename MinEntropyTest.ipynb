{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from MinEntropy import MitosisClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/root/projects/three_channel/Apply'\n",
    "mc = MitosisClassifier(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to run.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 53, in __getitem__\n    return collate([self._get_item(i) for i in idx]) if (isinstance(idx, Iterable) and not isinstance(idx, str)) else self._get_item(idx)\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 47, in _get_item\n    images = {name:kw['transform'](kw['aggregate'](kw['loader'](list(self.df.loc[idx,kw['cols']]))).squeeze()) for name,kw in self.opts['imageData'].items()}\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 47, in <dictcomp>\n    images = {name:kw['transform'](kw['aggregate'](kw['loader'](list(self.df.loc[idx,kw['cols']]))).squeeze()) for name,kw in self.opts['imageData'].items()}\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/utils/data_loading_utils.py\", line 13, in loadPILImages\n    with open(path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/allen/aics/modeling/PIPELINE/2018-07-23-17:20:57/3500000935_100X_20170524_1-Scene-09-P9-E05.czi_bbf6d11855956065d988671f5/3500000935_100X_20170524_1-Scene-09-P9-E05.czi_4.0_flat_proj.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0b8c36bc434e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/three_channel/MinEntropy.py\u001b[0m in \u001b[0;36mrun_me\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ready to run.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_models_xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/three_channel/MinEntropy.py\u001b[0m in \u001b[0;36mapply_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m                            } for k in self.dpX.dataloaders.keys()}\n\u001b[1;32m    183\u001b[0m         self.apply_single_model(self.dpX, self.modelX, mito_labels,\n\u001b[0;32m--> 184\u001b[0;31m                                 'x_pred_labels', 'x_pred_entropy', 'x_pred_uid', 'x_probability')\n\u001b[0m\u001b[1;32m    185\u001b[0m         self.apply_single_model(self.dpY, self.modelY, mito_labels,\n\u001b[1;32m    186\u001b[0m                                 'y_pred_labels', 'y_pred_entropy', 'y_pred_uid', 'y_probability')\n",
      "\u001b[0;32m~/projects/three_channel/MinEntropy.py\u001b[0m in \u001b[0;36mapply_single_model\u001b[0;34m(self, dp_h, model, mlabels, h_pred_labels, h_pred_entropy, h_pred_uid, h_probability)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_single_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pred_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pred_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdp_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uniqueID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 53, in __getitem__\n    return collate([self._get_item(i) for i in idx]) if (isinstance(idx, Iterable) and not isinstance(idx, str)) else self._get_item(idx)\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 47, in _get_item\n    images = {name:kw['transform'](kw['aggregate'](kw['loader'](list(self.df.loc[idx,kw['cols']]))).squeeze()) for name,kw in self.opts['imageData'].items()}\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/data_providers/DataframeDataset.py\", line 47, in <dictcomp>\n    images = {name:kw['transform'](kw['aggregate'](kw['loader'](list(self.df.loc[idx,kw['cols']]))).squeeze()) for name,kw in self.opts['imageData'].items()}\n  File \"/opt/pytorch_learning_tools/pytorch_learning_tools/utils/data_loading_utils.py\", line 13, in loadPILImages\n    with open(path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/allen/aics/modeling/PIPELINE/2018-07-23-17:20:57/3500000935_100X_20170524_1-Scene-09-P9-E05.czi_bbf6d11855956065d988671f5/3500000935_100X_20170524_1-Scene-09-P9-E05.czi_4.0_flat_proj.png'\n"
     ]
    }
   ],
   "source": [
    "mc.run_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
